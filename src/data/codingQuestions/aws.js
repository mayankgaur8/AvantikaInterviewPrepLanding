const aws = [
  { id: 'aws-1', title: 'Upload file to S3 (Node.js SDK v3)', statement: 'Upload a file to an S3 bucket using AWS SDK v3.', language: 'javascript', solution: `const { S3Client, PutObjectCommand } = require('@aws-sdk/client-s3');\nconst client = new S3Client({ region: 'us-east-1' });\nawait client.send(new PutObjectCommand({ Bucket: 'my-bucket', Key: 'file.txt', Body: Buffer.from('hello') }));` },
  { id: 'aws-2', title: 'Generate presigned URL for upload', statement: 'Create a presigned URL for clients to upload directly to S3.', language: 'javascript', solution: `const { S3Client, PutObjectCommand } = require('@aws-sdk/client-s3');\nconst { getSignedUrl } = require('@aws-sdk/s3-request-presigner');\nconst cmd = new PutObjectCommand({ Bucket:'b', Key:'k' });\nconst url = await getSignedUrl(client, cmd, { expiresIn: 3600 });` },
  { id: 'aws-3', title: 'Lambda handler (Node.js)', statement: 'Write a simple AWS Lambda handler that returns status 200.', language: 'javascript', solution: `exports.handler = async (event) => ({ statusCode: 200, body: JSON.stringify({ ok: true }) });` },
  { id: 'aws-4', title: 'API Gateway + Lambda integration (proxy)', statement: 'Configure API Gateway to invoke Lambda with proxy integration (concept).', language: 'text', solution: `Create a REST API (or HTTP API) and integrate route with Lambda; use proxy integration so event contains path, headers, body. Set IAM role for API to invoke Lambda if needed.` },
  { id: 'aws-5', title: 'IAM least-privilege policy', statement: 'Give an IAM policy that allows an EC2 instance to read specific S3 bucket objects only.', language: 'json', solution: `{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect":"Allow",
    "Action":["s3:GetObject"],
    "Resource":["arn:aws:s3:::my-bucket/*"]
  }]
}` },
  { id: 'aws-6', title: 'SQS queue consumer (Node.js)', statement: 'Poll SQS and process messages, deleting on success.', language: 'javascript', solution: `const { SQSClient, ReceiveMessageCommand, DeleteMessageCommand } = require('@aws-sdk/client-sqs');\nconst c = new SQSClient({});\nconst res = await c.send(new ReceiveMessageCommand({ QueueUrl, MaxNumberOfMessages: 10 }));\nfor (const m of res.Messages || []){ try { /* process */ await c.send(new DeleteMessageCommand({ QueueUrl, ReceiptHandle: m.ReceiptHandle })); } catch(e){ /* handle */ } }` },
  { id: 'aws-7', title: 'SQS FIFO & deduplication', statement: 'Use FIFO queue with message group id and deduplication to preserve ordering and avoid duplicates.', language: 'text', solution: `Create FIFO queue with .fifo name; send messages with MessageGroupId; use MessageDeduplicationId or enable content-based deduplication.` },
  { id: 'aws-8', title: 'SNS topic publish + SQS subscription', statement: 'Publish an event to SNS and fan-out to multiple SQS queues.', language: 'javascript', solution: `// Publish\nconst { SNSClient, PublishCommand } = require('@aws-sdk/client-sns');\nawait sns.send(new PublishCommand({ TopicArn, Message: JSON.stringify({ e:1 }) }));\n// Subscribe queues via console or Subscribe API` },
  { id: 'aws-9', title: 'DynamoDB put/get (Node.js)', statement: 'Write code to put and get an item in DynamoDB using SDK v3 DocumentClient.', language: 'javascript', solution: `const { DynamoDBClient } = require('@aws-sdk/client-dynamodb');\nconst { DynamoDBDocumentClient, PutCommand, GetCommand } = require('@aws-sdk/lib-dynamodb');\nconst client = DynamoDBDocumentClient.from(new DynamoDBClient({}));\nawait client.send(new PutCommand({ TableName:'t', Item:{ pk:'1', name:'a' } }));\nconst r = await client.send(new GetCommand({ TableName:'t', Key:{ pk:'1' } }));` },
  { id: 'aws-10', title: 'DynamoDB query with GSI', statement: 'Query items from a table using a Global Secondary Index.', language: 'javascript', solution: `await client.send(new QueryCommand({ TableName:'t', IndexName:'gsi1', KeyConditionExpression: 'gk = :v', ExpressionAttributeValues:{':v':'val'} }));` },
  { id: 'aws-11', title: 'DynamoDB transactional writes', statement: 'Perform atomic multi-item update using TransactWriteItems.', language: 'javascript', solution: `await client.send(new TransactWriteItemsCommand({ TransactItems:[ { Put:{ TableName:'t', Item:{ pk:'1', v:1 } } }, { Update:{ TableName:'t2', Key:{ pk:'x' }, UpdateExpression:'SET c = c + :one', ExpressionAttributeValues:{':one':1} } } ] }));` },
  { id: 'aws-12', title: 'CloudWatch custom metric (put metric data)', statement: 'Publish a custom metric to CloudWatch for monitoring.', language: 'javascript', solution: `const { CloudWatchClient, PutMetricDataCommand } = require('@aws-sdk/client-cloudwatch');\nawait cw.send(new PutMetricDataCommand({ Namespace:'MyApp', MetricData:[{ MetricName:'requests', Value:1, Unit:'Count' }] }));` },
  { id: 'aws-13', title: 'CloudWatch alarm for high error rate', statement: 'Create an alarm based on metric threshold and send to SNS topic.', language: 'text', solution: `Create metric filter or use existing metric; create alarm with threshold; set alarm actions to publish to SNS topic for notifications.` },
  { id: 'aws-14', title: 'CloudFormation basic stack (S3)', statement: 'Minimal CloudFormation template creating an S3 bucket.', language: 'yaml', solution: `Resources:\n  MyBucket:\n    Type: AWS::S3::Bucket\n    Properties:\n      BucketName: my-bucket-example` },
  { id: 'aws-15', title: 'CDK construct example (TypeScript)', statement: 'Create an S3 bucket and Lambda using AWS CDK.', language: 'typescript', solution: `const bucket = new s3.Bucket(this,'b');\nconst fn = new lambda.Function(this,'f',{ runtime: lambda.Runtime.NODEJS_18_X, code: lambda.Code.fromAsset('lambda'), handler:'index.handler', environment:{ BUCKET: bucket.bucketName } });\nbucket.grantReadWrite(fn);` },
  { id: 'aws-16', title: 'ECS Fargate task definition (sketch)', statement: 'Run a container on ECS Fargate with a task definition and service.', language: 'text', solution: `Define task definition with container image, CPU/memory; create Fargate service attached to an ALB target group; ensure subnets and security groups allow traffic.` },
  { id: 'aws-17', title: 'EKS deploy basic (kubectl)', statement: 'Deploy an app to EKS cluster using kubectl and a Deployment manifest.', language: 'yaml', solution: `apiVersion: apps/v1\nkind: Deployment\nmetadata: name: app\nspec: replicas:2 template: spec: containers: - name: app image: myimage:latest` },
  { id: 'aws-18', title: 'RDS connect from Lambda (best practice)', statement: 'Connect to RDS securely from Lambda with VPC configuration and IAM auth (sketch).', language: 'text', solution: `Place Lambda in same VPC subnets with ENIs; use RDS Proxy to manage connections and supply IAM auth for short-lived credentials where supported.` },
  { id: 'aws-19', title: 'Parameter Store vs Secrets Manager', statement: 'When to use SSM Parameter Store vs Secrets Manager for secrets/config.', language: 'text', solution: `Use Parameter Store for config/plaintext and simple secure strings; use Secrets Manager for rotation, fine-grained secret lifecycle and higher cost but features.` },
  { id: 'aws-20', title: 'Kinesis Data Streams - producer example', statement: 'Put a record to a Kinesis stream from Node.js.', language: 'javascript', solution: `const { PutRecordCommand } = require('@aws-sdk/client-kinesis');\nawait kinesis.send(new PutRecordCommand({ StreamName, PartitionKey:'k', Data: Buffer.from('payload') }));` },
  { id: 'aws-21', title: 'Kinesis consumer (enhanced fan-out or lambda)', statement: 'Consume records using Lambda event source or KCL (sketch).', language: 'text', solution: `Configure Lambda as event source mapping for stream or use KCL/Enhanced Fan-Out consumers for high throughput; handle checkpointing and retries.` },
  { id: 'aws-22', title: 'Step Functions simple workflow', statement: 'Compose a Step Functions state machine calling two Lambda tasks sequentially.', language: 'json', solution: `{
  "StartAt":"Task1",
  "States":{
    "Task1":{ "Type":"Task","Resource":"arn:aws:lambda:...:function:fn1","Next":"Task2" },
    "Task2":{ "Type":"Task","Resource":"arn:aws:lambda:...:function:fn2","End":true }
  }
}` },
  { id: 'aws-23', title: 'CloudFront with S3 origin', statement: 'Serve static content from S3 via CloudFront and set caching headers.', language: 'text', solution: `Create CloudFront distribution with S3 bucket origin; configure behaviors and TTL; set Cache-Control headers on objects; optionally use OAI or OAC for private buckets.` },
  { id: 'aws-24', title: 'Route53 simple record', statement: 'Create an A record mapping example.com to an IP or alias to CloudFront.', language: 'text', solution: `Use Route53 hosted zone; create A/AAAA record; for CloudFront use Alias record to distribution.` },
  { id: 'aws-25', title: 'ACM certificate usage', statement: 'Request a public certificate in ACM and attach to CloudFront or ALB.', language: 'text', solution: `Request certificate in us-east-1 for CloudFront; validate via DNS; attach ARN to distribution or load balancer listener for HTTPS.` },
  { id: 'aws-26', title: 'ECR push/pull workflow', statement: 'Build Docker image and push to ECR, then pull on ECS/EKS.', language: 'bash', solution: `aws ecr get-login-password | docker login --username AWS --password-stdin <account>.dkr.ecr.region.amazonaws.com\ndocker build -t repo:tag .\ndocker tag repo:tag <account>.dkr.ecr.region.amazonaws.com/repo:tag\ndocker push ...` },
  { id: 'aws-27', title: 'IAM role for service (EC2 assume role)', statement: 'Attach an instance profile to EC2 and use role credentials from metadata service.', language: 'text', solution: `Create IAM role with policy, create instance profile, attach to EC2. SDKs will use instance metadata to obtain temporary credentials automatically.` },
  { id: 'aws-28', title: 'VPC Subnets and NAT', statement: 'Explain public/private subnets and how NAT Gateway enables private instances to access internet.', language: 'text', solution: `Place public subnets with route to Internet Gateway for public-facing resources. Private subnets route to NAT Gateway in public subnet to allow outbound internet while keeping resources private.` },
  { id: 'aws-29', title: 'VPC endpoint for S3 (gateway)', statement: 'Use a VPC gateway endpoint for S3 to avoid internet egress.', language: 'text', solution: `Create VPC endpoint of type Gateway for com.amazonaws.<region>.s3 and add route entries for endpoint to private subnet route tables; configure bucket policy to restrict to VPC endpoint.` },
  { id: 'aws-30', title: 'Security group example', statement: 'Allow HTTP from anywhere and SSH from a single IP in a security group.', language: 'text', solution: `Ingress rules: TCP 80 0.0.0.0/0; TCP 22 x.x.x.x/32. Keep egress permissive or restrict as needed.` },
  { id: 'aws-31', title: 'S3 lifecycle rules and versioning', statement: 'Configure lifecycle to transition objects to Glacier and enable versioning.', language: 'text', solution: `Enable bucket versioning; add lifecycle rule with transition to GLACIER after N days and expiration after M days for noncurrent versions.` },
  { id: 'aws-32', title: 'S3 event notifications to Lambda', statement: 'Trigger a Lambda when an object is created in S3.', language: 'text', solution: `Configure bucket notifications or use S3 console to add Lambda function as destination for s3:ObjectCreated:* events; ensure Lambda has permission to be invoked by S3.` },
  { id: 'aws-33', title: 'Multipart upload to S3', statement: 'Upload large files using multipart upload (sketch).', language: 'text', solution: `Initiate multipart upload, upload parts in parallel, complete multipart upload with ETags. SDKs have helper APIs to manage this.` },
  { id: 'aws-34', title: 'SES send email (verified domain)', statement: 'Send email using Amazon SES from a verified domain.', language: 'javascript', solution: `const { SESClient, SendEmailCommand } = require('@aws-sdk/client-ses');\nawait ses.send(new SendEmailCommand({ Destination:{ ToAddresses:['to@x'] }, Message:{ Subject:{ Data:'Hi' }, Body:{ Text:{ Data:'Body' } } }, Source:'no-reply@yourdomain.com' }));` },
  { id: 'aws-35', title: 'CloudTrail for auditing', statement: 'Enable CloudTrail to log account API activity to S3 and optionally to CloudWatch Logs.', language: 'text', solution: `Create a trail and specify S3 bucket for delivery; enable management and data events as needed; integrate with CloudWatch for alerting on suspicious activity.` },
  { id: 'aws-36', title: 'Config rules example', statement: 'Use AWS Config to evaluate resource compliance (e.g., S3 buckets must have encryption).', language: 'text', solution: `Enable AWS Config recorder and add managed rule s3-bucket-server-side-encryption-enabled; review compliance results and remediate.` },
  { id: 'aws-37', title: 'Cost optimization tip (EC2)', statement: 'How to save cost on EC2: reserved instances, savings plans, right-sizing, spot instances.', language: 'text', solution: `Use Savings Plans for steady-state, use Spot for fault-tolerant workloads, right-size instances and turn off non-production resources.` },
  { id: 'aws-38', title: 'Auto Scaling policy (target tracking)', statement: 'Configure Auto Scaling group with target tracking on average CPU.', language: 'text', solution: `Create ASG with scaling policy type TargetTrackingScaling and target value (e.g., CPUUtilization 50%). ASG adjusts desired capacity to meet target.` },
  { id: 'aws-39', title: 'ALB health checks', statement: 'Configure ALB target group health checks and path to use for readiness.', language: 'text', solution: `Set health check path (/health), protocol HTTP, healthy/unhealthy thresholds, and interval. Ensure instances respond quickly to avoid flapping.` },
  { id: 'aws-40', title: 'EBS snapshot & restore', statement: 'Create EBS snapshot and restore a volume from a snapshot.', language: 'bash', solution: `aws ec2 create-snapshot --volume-id vol-123\naws ec2 create-volume --snapshot-id snap-123 --availability-zone us-east-1a` },
  { id: 'aws-41', title: 'RDS read replica (MySQL)', statement: 'Create read replica for scaling read traffic.', language: 'text', solution: `Enable automated backups on primary; create read replica which uses replication to keep in sync; direct read queries to replicas.` },
  { id: 'aws-42', title: 'RDS Multi-AZ vs read replica', statement: 'Explain difference: Multi-AZ for high availability; read replica for scaling reads.', language: 'text', solution: `Multi-AZ replicates synchronously for failover (no read scaling). Read replicas are asynchronous and used to scale reads, not for HA.` },
  { id: 'aws-43', title: 'EFS mount to EC2', statement: 'Mount EFS file system to an EC2 instance using mount target and NFS.', language: 'bash', solution: `sudo yum install -y amazon-efs-utils\nsudo mkdir /mnt/efs\nsudo mount -t efs fs-123:/ /mnt/efs` },
  { id: 'aws-44', title: 'EFS with Lambda (access)', statement: 'Attach EFS to Lambda for large code or shared storage.', language: 'text', solution: `Create EFS access point, mount targets in VPC, configure Lambda function to use file system (in same VPC) and set mount path in Lambda config.` },
  { id: 'aws-45', title: 'AWS WAF basic rule', statement: 'Block requests containing SQLi patterns using a WAF rule.', language: 'text', solution: `Create WAF WebACL with a managed rule group or custom regex rule to inspect body/URI and block matching SQL injection patterns; associate with CloudFront or ALB.` },
  { id: 'aws-46', title: 'AWS Shield vs WAF', statement: 'Explain Shield Standard vs WAF and when to use Shield Advanced.', language: 'text', solution: `Shield Standard protects against common DDoS automatically. Use Shield Advanced for enhanced protection, DDoS cost protection, and 24/7 response with additional fee.` },
  { id: 'aws-47', title: 'Cross-account S3 access (bucket policy)', statement: 'Grant read access to a specific IAM role from another AWS account.', language: 'json', solution: `{
  "Statement":[{ "Effect":"Allow","Principal":{"AWS":"arn:aws:iam::ACCOUNT_ID:role/RoleName"},"Action":["s3:GetObject"],"Resource":["arn:aws:s3:::my-bucket/*"] }]
}` },
  { id: 'aws-48', title: 'KMS encrypt/decrypt (Node.js)', statement: 'Encrypt/decrypt a small blob using AWS KMS.', language: 'javascript', solution: `const { KMSClient, EncryptCommand, DecryptCommand } = require('@aws-sdk/client-kms');\nconst kms = new KMSClient({});\nconst enc = await kms.send(new EncryptCommand({ KeyId:'alias/mykey', Plaintext: Buffer.from('secret') }));\nconst dec = await kms.send(new DecryptCommand({ CiphertextBlob: enc.CiphertextBlob }));` },
  { id: 'aws-49', title: 'S3 server-side encryption (SSE-KMS)', statement: 'Enable SSE-KMS for sensitive objects in S3 and grant decrypt permissions to a role.', language: 'text', solution: `Enable bucket default encryption SSE-KMS and use a KMS key; grant kms:Decrypt to IAM principals that need to read objects; restrict key usage via key policy.` },
  { id: 'aws-50', title: 'Automated backups and restore testing', statement: 'Demonstrate setting up automated snapshots and periodically testing restores.', language: 'text', solution: `Schedule snapshots via lifecycle or backup service (AWS Backup); automate restore tests in non-prod account to verify backups are valid and perform periodic restore drills.` }
];

export default aws;
